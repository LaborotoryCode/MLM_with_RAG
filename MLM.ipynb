{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install transformers\n",
    "!{sys.executable} -m pip install tensorflow\n",
    "!{sys.executable} -m pip install transformers==4.37.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFBertForMaskedLM, BertTokenizerFast\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MAE\n",
    "import random\n",
    "\n",
    "max_seq_length = 20\n",
    "masking_probability = 0.35  # Probability of masking a word\n",
    "\n",
    "# Load pre-trained tokenizer and model\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "model = TFBertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to mask random words\n",
    "def create_masked_input(text):\n",
    "  input_ids = tokenizer.encode(text, add_special_tokens=True, max_length=max_seq_length, truncation=True, padding='max_length')\n",
    "  labels = input_ids.copy()\n",
    "\n",
    "  # Mask random words\n",
    "  for i in range(len(input_ids)):\n",
    "    if random.random() < masking_probability:\n",
    "      if input_ids[i] not in tokenizer.special_tokens_map.values():  # Skip special tokens\n",
    "        temp = model.config.vocab_size\n",
    "        if temp == 30522:\n",
    "          labels[i] = temp-1\n",
    "        else:\n",
    "          labels[i] = temp  # Replace with masking label\n",
    "        input_ids[i] = tokenizer.mask_token_id\n",
    "\n",
    "  return input_ids, labels\n",
    "\n",
    "global training_data\n",
    "\n",
    "kai_messages = \"\"\n",
    "training_data = []\n",
    "\n",
    "with open(\"/content/_chat.txt\", \"r\") as fin:\n",
    "\n",
    "    for i in range(1022):\n",
    "      line = fin.readline()\n",
    "      if \"Ayaan\" not in line:\n",
    "        line = line[26::]\n",
    "        kai_messages+=line\n",
    "        input_ids, labels = create_masked_input(kai_messages)\n",
    "        training_data.append((input_ids, labels))\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers, layers\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "x_train, y_train = zip(*training_data)\n",
    "x_train = tf.convert_to_tensor(x_train)\n",
    "y_train = tf.convert_to_tensor(y_train)\n",
    "\n",
    "# Define model inputs\n",
    "input_word_ids = Input(shape=(max_seq_length,), dtype=tf.int32)\n",
    "\n",
    "# Pass through pre-trained model\n",
    "outputs = model(input_word_ids)[-1]  # Access the masked language modeling output\n",
    "\n",
    "# Define the model\n",
    "model_local = Model(inputs=input_word_ids, outputs=outputs)\n",
    "\n",
    "#tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "# Compile the model\n",
    "model_local.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), optimizer=Adam(learning_rate=2e-5))\n",
    "\n",
    "# Train the model\n",
    "history = model_local.fit(x_train, y_train, epochs=4, batch_size=16)  # Adjust epochs and batch size as needed\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df[\"loss\"].plot()\n",
    "\n",
    "# Save the model\n",
    "model_local.sa\n",
    "model_local.save(\"my_mlm_model\")\n",
    "model.config.save_pretrained(\"/content/my_mlm_model/config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call model in this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFBertForMaskedLM, BertTokenizer\n",
    "\n",
    "# Replace 'bert-base-uncased' with your desired pre-trained model name\n",
    "model = TFBertForMaskedLM.from_pretrained(\"/content/my_mlm_model\")\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "\n",
    "prompt = \"Today is a beautiful day because [MASK] is happening.\"\n",
    "\n",
    "# Tokenize the prompt (optional, depending on the model)\n",
    "encoded_prompt = tokenizer(prompt, return_tensors='tf')\n",
    "input_ids = encoded_prompt['input_ids']\n",
    "\n",
    "predictions = model(input_ids)[7]  # Assuming the mask is at index 0\n",
    "predicted_index = tf.math.argmax(predictions[0]).numpy()\n",
    "predicted_word = tokenizer.convert_ids_to_tokens(predicted_index)[7]  # Assuming mask is at index 1\n",
    "\n",
    "print(predicted_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test model\n",
    "from transformers import BertTokenizer\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define your prompt\n",
    "prompt = \"My favorite person is [MASK]\"\n",
    "\n",
    "# Load tokenizer (replace with your model name)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Pad the prompt sequence (assuming max_len is 20)\n",
    "max_len = 20\n",
    "padded_prompt = tokenizer(prompt, padding='longest', max_length=20, return_tensors='tf')\n",
    "input_ids = padded_prompt['input_ids']  # Access encoded input IDs\n",
    "\n",
    "model = TFBertForMaskedLM.from_pretrained(\"enter path of model\")\n",
    "\n",
    "# Generate predictions\n",
    "predictions = model(input_ids)[0]\n",
    "print(predictions)\n",
    "\n",
    "# Decode the predicted word\n",
    "#predicted_index = tf.math.argmax(predictions[0][1]).numpy()\n",
    "predicted_index = tf.math.argmax(predictions[0]).numpy()  # Assuming mask is at index 1\n",
    "predicted_word = tokenizer.convert_ids_to_tokens(predicted_index)[1]\n",
    "print(predicted_word)\n",
    "\n",
    "# Print the completed prompt\n",
    "completed_prompt = prompt.replace(\"[MASK]\", predicted_word)\n",
    "print(f\"Completed Prompt: {completed_prompt}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
